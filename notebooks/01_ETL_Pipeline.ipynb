{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š TELECOM X - CHURN ANALYSIS PROJECT\n",
    "## ğŸ”„ Notebook 01: ETL Pipeline (Extract, Transform, Load)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ **Objetivos:**\n",
    "1. ğŸ“¥ **Extraer** datos de mÃºltiples fuentes (APIs, CSV, mock data)\n",
    "2. ğŸ”§ **Transformar** y limpiar los datos\n",
    "3. âœ… **Validar** calidad de datos\n",
    "4. ğŸ’¾ **Cargar** datos procesados\n",
    "5. ğŸŒ **Enriquecer** con APIs externas\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‘¤ Desarrollado por:** Elizabeth DÃ­az Familia  \n",
    "**ğŸ“… Fecha:** 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necesarios\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ“¦ LibrerÃ­as importadas exitosamente\")\n",
    "print(f\"ğŸ Pandas: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ 1. EXTRACCIÃ“N DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“¥ FASE 1: EXTRACCIÃ“N DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# OpciÃ³n 1: Generar datos mock para demostraciÃ³n\n",
    "def generate_mock_telecom_data(n_customers=1000):\n",
    "    \"\"\"Generar datos mock de clientes de telecomunicaciones\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'CustomerID': [f'CUST{i:05d}' for i in range(1, n_customers + 1)],\n",
    "        'Gender': np.random.choice(['Male', 'Female'], n_customers),\n",
    "        'SeniorCitizen': np.random.choice([0, 1], n_customers, p=[0.84, 0.16]),\n",
    "        'Partner': np.random.choice(['Yes', 'No'], n_customers, p=[0.48, 0.52]),\n",
    "        'Dependents': np.random.choice(['Yes', 'No'], n_customers, p=[0.30, 0.70]),\n",
    "        'tenure': np.random.randint(1, 73, n_customers),\n",
    "        'PhoneService': np.random.choice(['Yes', 'No'], n_customers, p=[0.90, 0.10]),\n",
    "        'MultipleLines': np.random.choice(['Yes', 'No', 'No phone service'], n_customers),\n",
    "        'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_customers, p=[0.34, 0.44, 0.22]),\n",
    "        'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'OnlineBackup': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'DeviceProtection': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'TechSupport': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'StreamingTV': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'StreamingMovies': np.random.choice(['Yes', 'No', 'No internet'], n_customers),\n",
    "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_customers, p=[0.55, 0.21, 0.24]),\n",
    "        'PaperlessBilling': np.random.choice(['Yes', 'No'], n_customers, p=[0.59, 0.41]),\n",
    "        'PaymentMethod': np.random.choice(\n",
    "            ['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'],\n",
    "            n_customers,\n",
    "            p=[0.34, 0.23, 0.22, 0.21]\n",
    "        ),\n",
    "        'MonthlyCharges': np.random.uniform(18.0, 120.0, n_customers),\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # TotalCharges basado en tenure y MonthlyCharges\n",
    "    df['TotalCharges'] = df['tenure'] * df['MonthlyCharges'] + np.random.uniform(-50, 50, n_customers)\n",
    "    df['TotalCharges'] = df['TotalCharges'].clip(lower=0)\n",
    "    \n",
    "    # Churn con lÃ³gica realista\n",
    "    churn_prob = 0.27  # base probability\n",
    "    \n",
    "    # Factores que afectan churn\n",
    "    churn_factors = np.zeros(n_customers)\n",
    "    churn_factors += (df['Contract'] == 'Month-to-month').astype(int) * 0.3\n",
    "    churn_factors += (df['tenure'] < 12).astype(int) * 0.2\n",
    "    churn_factors += (df['InternetService'] == 'Fiber optic').astype(int) * 0.1\n",
    "    churn_factors += (df['SeniorCitizen'] == 1).astype(int) * 0.1\n",
    "    \n",
    "    df['Churn'] = np.random.random(n_customers) < (churn_prob + churn_factors * 0.5)\n",
    "    df['Churn'] = df['Churn'].map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generar datos\n",
    "df_raw = generate_mock_telecom_data(n_customers=1000)\n",
    "\n",
    "print(f\"\\nâœ… Datos generados: {len(df_raw):,} registros\")\n",
    "print(f\"ğŸ“Š Columnas: {len(df_raw.columns)}\")\n",
    "print(f\"\\nğŸ“‹ Primeras filas:\")\n",
    "display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 2. ANÃLISIS INICIAL DE CALIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ” ANÃLISIS INICIAL DE CALIDAD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# InformaciÃ³n general\n",
    "print(\"\\nğŸ“Š InformaciÃ³n del Dataset:\")\n",
    "print(df_raw.info())\n",
    "\n",
    "# Valores nulos\n",
    "print(\"\\nğŸ” Valores Nulos:\")\n",
    "null_counts = df_raw.isnull().sum()\n",
    "if null_counts.sum() > 0:\n",
    "    print(null_counts[null_counts > 0])\n",
    "else:\n",
    "    print(\"âœ… No hay valores nulos\")\n",
    "\n",
    "# Duplicados\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"\\nğŸ“‹ Registros Duplicados: {duplicates}\")\n",
    "\n",
    "# EstadÃ­sticas descriptivas\n",
    "print(\"\\nğŸ“ˆ EstadÃ­sticas Descriptivas:\")\n",
    "display(df_raw.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ 3. TRANSFORMACIÃ“N DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”§ FASE 2: TRANSFORMACIÃ“N DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Copiar dataframe\n",
    "df_transformed = df_raw.copy()\n",
    "\n",
    "# 1. Estandarizar nombres de columnas\n",
    "print(\"\\n1ï¸âƒ£ Estandarizando nombres de columnas...\")\n",
    "df_transformed.columns = df_transformed.columns.str.strip()\n",
    "\n",
    "# 2. Convertir tipos de datos\n",
    "print(\"2ï¸âƒ£ Convirtiendo tipos de datos...\")\n",
    "df_transformed['SeniorCitizen'] = df_transformed['SeniorCitizen'].astype(str).map({'0': 'No', '1': 'Yes'})\n",
    "df_transformed['MonthlyCharges'] = df_transformed['MonthlyCharges'].round(2)\n",
    "df_transformed['TotalCharges'] = df_transformed['TotalCharges'].round(2)\n",
    "\n",
    "# 3. Crear variables derivadas\n",
    "print(\"3ï¸âƒ£ Creando variables derivadas...\")\n",
    "\n",
    "# Tenure groups\n",
    "df_transformed['TenureGroup'] = pd.cut(\n",
    "    df_transformed['tenure'],\n",
    "    bins=[0, 12, 24, 48, 73],\n",
    "    labels=['0-12 months', '12-24 months', '24-48 months', '48+ months']\n",
    ")\n",
    "\n",
    "# Charges groups\n",
    "df_transformed['ChargesGroup'] = pd.cut(\n",
    "    df_transformed['MonthlyCharges'],\n",
    "    bins=[0, 35, 70, 120],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Total services\n",
    "service_cols = ['PhoneService', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "df_transformed['TotalServices'] = 0\n",
    "for col in service_cols:\n",
    "    if col in df_transformed.columns:\n",
    "        df_transformed['TotalServices'] += (df_transformed[col] == 'Yes').astype(int)\n",
    "\n",
    "# Customer Lifetime Value (CLV) estimate\n",
    "df_transformed['CLV_Estimate'] = df_transformed['TotalCharges'] * 1.2  # Simple estimate\n",
    "\n",
    "print(\"\\nâœ… Transformaciones completadas\")\n",
    "print(f\"ğŸ“Š Nuevas columnas: {len(df_transformed.columns) - len(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ 4. ENRIQUECIMIENTO CON APIs EXTERNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸŒ FASE 3: ENRIQUECIMIENTO CON APIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# API 1: Exchange Rates\n",
    "print(\"\\nğŸ’± Obteniendo tasas de cambio...\")\n",
    "try:\n",
    "    response = requests.get('https://api.exchangerate-api.com/v4/latest/USD', timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        exchange_data = response.json()\n",
    "        usd_to_eur = exchange_data['rates'].get('EUR', 0.85)\n",
    "        \n",
    "        # Agregar columnas con conversiÃ³n\n",
    "        df_transformed['MonthlyCharges_EUR'] = (df_transformed['MonthlyCharges'] * usd_to_eur).round(2)\n",
    "        df_transformed['TotalCharges_EUR'] = (df_transformed['TotalCharges'] * usd_to_eur).round(2)\n",
    "        \n",
    "        print(f\"âœ… Tasa USD/EUR aplicada: {usd_to_eur}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No se pudo obtener tasas de cambio\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error en API de tasas: {str(e)}\")\n",
    "\n",
    "# Agregar timestamp de procesamiento\n",
    "df_transformed['DataProcessedAt'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(\"\\nâœ… Enriquecimiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… 5. VALIDACIÃ“N DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"âœ… FASE 4: VALIDACIÃ“N DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validation_results = {\n",
    "    'total_records': len(df_transformed),\n",
    "    'total_columns': len(df_transformed.columns),\n",
    "    'null_values': df_transformed.isnull().sum().sum(),\n",
    "    'duplicates': df_transformed.duplicated().sum(),\n",
    "    'churn_distribution': df_transformed['Churn'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“Š Resultados de ValidaciÃ³n:\")\n",
    "print(f\"âœ“ Total de registros: {validation_results['total_records']:,}\")\n",
    "print(f\"âœ“ Total de columnas: {validation_results['total_columns']}\")\n",
    "print(f\"âœ“ Valores nulos: {validation_results['null_values']}\")\n",
    "print(f\"âœ“ Duplicados: {validation_results['duplicates']}\")\n",
    "print(f\"\\nâœ“ DistribuciÃ³n de Churn:\")\n",
    "for status, count in validation_results['churn_distribution'].items():\n",
    "    percentage = (count / validation_results['total_records']) * 100\n",
    "    print(f\"   {status}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Validaciones especÃ­ficas\n",
    "print(\"\\nğŸ” Validaciones EspecÃ­ficas:\")\n",
    "\n",
    "# 1. MonthlyCharges debe ser > 0\n",
    "invalid_charges = (df_transformed['MonthlyCharges'] <= 0).sum()\n",
    "print(f\"âœ“ MonthlyCharges invÃ¡lidos: {invalid_charges}\")\n",
    "\n",
    "# 2. Tenure debe estar en rango vÃ¡lido\n",
    "invalid_tenure = ((df_transformed['tenure'] < 0) | (df_transformed['tenure'] > 72)).sum()\n",
    "print(f\"âœ“ Tenure invÃ¡lidos: {invalid_tenure}\")\n",
    "\n",
    "# 3. CustomerID Ãºnico\n",
    "unique_customers = df_transformed['CustomerID'].nunique()\n",
    "print(f\"âœ“ CustomerID Ãºnicos: {unique_customers}/{len(df_transformed)}\")\n",
    "\n",
    "if validation_results['null_values'] == 0 and validation_results['duplicates'] == 0:\n",
    "    print(\"\\nğŸ‰ Â¡ValidaciÃ³n exitosa! Datos listos para anÃ¡lisis.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Se encontraron problemas en la validaciÃ³n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 6. CARGA DE DATOS PROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ’¾ FASE 5: CARGA DE DATOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Crear directorios si no existen\n",
    "Path('data/raw').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar datos raw\n",
    "raw_path = 'data/raw/telecom_churn_raw.csv'\n",
    "df_raw.to_csv(raw_path, index=False)\n",
    "print(f\"\\nâœ“ Datos raw guardados: {raw_path}\")\n",
    "print(f\"  TamaÃ±o: {len(df_raw):,} registros\")\n",
    "\n",
    "# Guardar datos procesados\n",
    "processed_path = 'data/processed/telecom_churn_clean.csv'\n",
    "df_transformed.to_csv(processed_path, index=False)\n",
    "print(f\"\\nâœ“ Datos procesados guardados: {processed_path}\")\n",
    "print(f\"  TamaÃ±o: {len(df_transformed):,} registros\")\n",
    "print(f\"  Columnas: {len(df_transformed.columns)}\")\n",
    "\n",
    "# Guardar tambiÃ©n en formato parquet (mÃ¡s eficiente)\n",
    "parquet_path = 'data/processed/telecom_churn_clean.parquet'\n",
    "df_transformed.to_parquet(parquet_path, index=False)\n",
    "print(f\"\\nâœ“ Datos guardados en Parquet: {parquet_path}\")\n",
    "\n",
    "# Guardar metadata\n",
    "metadata = {\n",
    "    'processed_at': datetime.now().isoformat(),\n",
    "    'total_records': len(df_transformed),\n",
    "    'total_columns': len(df_transformed.columns),\n",
    "    'columns': list(df_transformed.columns),\n",
    "    'churn_rate': (df_transformed['Churn'] == 'Yes').mean(),\n",
    "    'validation': validation_results\n",
    "}\n",
    "\n",
    "metadata_path = 'data/processed/metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "print(f\"\\nâœ“ Metadata guardada: {metadata_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Â¡Pipeline ETL completado exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 7. RESUMEN DEL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š RESUMEN DEL PIPELINE ETL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nâœ… FASES COMPLETADAS:\")\n",
    "print(\"  1ï¸âƒ£ ExtracciÃ³n de datos\")\n",
    "print(\"  2ï¸âƒ£ TransformaciÃ³n y limpieza\")\n",
    "print(\"  3ï¸âƒ£ Enriquecimiento con APIs\")\n",
    "print(\"  4ï¸âƒ£ ValidaciÃ³n de calidad\")\n",
    "print(\"  5ï¸âƒ£ Carga de datos procesados\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ MÃ‰TRICAS:\")\n",
    "print(f\"  ğŸ“Š Registros procesados: {len(df_transformed):,}\")\n",
    "print(f\"  ğŸ“‹ Columnas originales: {len(df_raw.columns)}\")\n",
    "print(f\"  ğŸ“‹ Columnas finales: {len(df_transformed.columns)}\")\n",
    "print(f\"  â• Columnas agregadas: {len(df_transformed.columns) - len(df_raw.columns)}\")\n",
    "print(f\"  ğŸ’¹ Tasa de Churn: {(df_transformed['Churn'] == 'Yes').mean():.2%}\")\n",
    "\n",
    "print(\"\\nğŸ“ ARCHIVOS GENERADOS:\")\n",
    "print(f\"  âœ“ {raw_path}\")\n",
    "print(f\"  âœ“ {processed_path}\")\n",
    "print(f\"  âœ“ {parquet_path}\")\n",
    "print(f\"  âœ“ {metadata_path}\")\n",
    "\n",
    "print(\"\\nğŸš€ SIGUIENTE PASO:\")\n",
    "print(\"  Ejecutar 02_EDA_Exploratory_Analysis.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ CONCLUSIÃ“N\n",
    "\n",
    "âœ… Pipeline ETL ejecutado exitosamente  \n",
    "âœ… Datos extraÃ­dos, transformados y cargados  \n",
    "âœ… Calidad de datos validada  \n",
    "âœ… Enriquecimiento con APIs completado  \n",
    "\n",
    "**Dataset final listo para anÃ¡lisis exploratorio.**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’œ Desarrollado con â¤ï¸ por Elizabeth DÃ­az Familia\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
